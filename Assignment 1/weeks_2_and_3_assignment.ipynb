{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlqVBEfLBOF_"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 2 and 3: Assignment (200 points + 20 bonus points + 1 bonus point for each bug you find and another bonus point if you debug it and before you ask, no, typos unfortunately are not considered bugs - first come, first served)*  \n",
    "Author: Umut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rT8BaKk5CpeB"
   },
   "outputs": [],
   "source": [
    "# Group number: 6\n",
    "# Student 1 name, student 1 number: Aumkar Lele, s4743962\n",
    "# Student 2 name, student 2 number: Djamari Oetringer, s4464559\n",
    "# Student 3 name, student 3 number: Daphne Lenders, s4433556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86zZctPu1K2M"
   },
   "source": [
    "**Packages (10 points)**  \n",
    "In this cell, you will import the required packages.  \n",
    "*Tasks*   \n",
    "- (1) It is always good practice to first think about the big picture and not rush into writing code before clearly knowing everything that you will have to do so as to avoid future complications. Therefore, your first task is to study the skeleton code and come up with a plan of how to proceed. (**0 points**)\n",
    "- (2) However, I agree that doing so is arguably the most boring part of coding, and you rather skip it. To help you to resist the temptation of skipping going through the skeleton code, I have removed the import statements. Your second task is to Identify the required packages and import them. Note that if you are using Python 2.7, you should import print from the future. (**10 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBiJw5pV030o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cupy as cp\n",
    "from chainer.serializers import load_npz, save_npz\n",
    "from chainer.optimizers import Adam\n",
    "from chainer import ChainList, Chain, iterators\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "from chainer.dataset import concat_examples, DatasetMixin\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00iIAIv37Del"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "batch_test = 3\n",
    "root_dir = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "data_directory = os.path.join(root_dir, 'lfw-deepfunneled') # Make a directory to store the data and enter it here.\n",
    "                    # We will be using a smaller dataset (LFW) than the one used in the paper (CelebA) for computational resource considerations.\n",
    "                    # Download it from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz.\n",
    "resize_dir = os.path.join(root_dir, 'Resized_images')\n",
    "device = 0\n",
    "epochs = 5\n",
    "lambda_ = {'feature': 1., 'pixel': 1., 'total_variation': 1e-5}\n",
    "model_directory = os.path.join(root_dir, 'NIPS_model_ass1') # Make a directory to store the models and enter it here. Move Vgg4Layers.npz to the model directory.\n",
    "outsize = (96, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOhjvsOx9lJY"
   },
   "source": [
    "**Preprocessing functions (10 points + 5 bonus points)** (taken from https://github.com/mbeyeler/opencv-python-blueprints)  \n",
    "In the following cell, you will implement some of the preprocessing functions. The rest of the preprocessing steps have already been applied to the data.  \n",
    "*Tasks*\n",
    "- (1) Implement the resizing operation. That is, you should extract the data, resize each portrait to 96 pixels x 96 pixels and save them to the data directory as JPG. (**10 points **)\n",
    "- (2) The pencil sketch class implements the sketch effect in a simpler way than the one mentioned in the lecture. Explain how/why the used operations (blur and divide) convert portraits to sketches, and how it differs from that which was mentioned in the lecture? (**5 bonus points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Resizing and saving each portrait in the data directory\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "for root, dirs, files in os.walk(data_directory):\n",
    "    for fname in files:\n",
    "\n",
    "        filepath = os.path.join(root, fname)\n",
    "        \n",
    "        img = cv2.imread(filepath)\n",
    "        \n",
    "        img1 = cv2.resize(img, (96, 96))\n",
    "        \n",
    "        cv2.imwrite(os.path.join(resize_dir, '%r_1.jpg' %iterator), img1)\n",
    "        \n",
    "        iterator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY4lbpLK9kp4"
   },
   "outputs": [],
   "source": [
    "# (1) start\n",
    "\n",
    "# .\n",
    "# .\n",
    "# (1) end\n",
    "\n",
    "class PencilSketch:\n",
    "    \"\"\"Pencil sketch effect\n",
    "        A class that applies a pencil sketch effect to an image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimension):\n",
    "        \"\"\"Initialize parameters\n",
    "            :param (width, height): Image size.\n",
    "        \"\"\"\n",
    "        self.width, self.height = dimension\n",
    "\n",
    "       \n",
    "\n",
    "    def render(self, img_rgb):\n",
    "        \"\"\"Applies pencil sketch effect to an RGB image\n",
    "            :param img_rgb: RGB image to be processed\n",
    "            :returns: Processed RGB image\n",
    "        \"\"\"\n",
    "        img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (21, 21), 0, 0)\n",
    "        img_blend = cv2.divide(img_gray, img_blur, scale=256)\n",
    "\n",
    "        # return cv2.cvtColor(img_blend, cv2.COLOR_GRAY2RGB)\n",
    "        return img_blend\n",
    "\n",
    "def pencil_sketch(img_rgb):\n",
    "    pencilSketch = PencilSketch((img_rgb.shape[1], img_rgb.shape[0]))\n",
    "\n",
    "    return pencilSketch.render(img_rgb)\n",
    "\n",
    "# (2) Write your answer here.\n",
    "'''\n",
    "In the original paper, the following steps were taken:\n",
    "1) Convert the original image to a grayscale image. -> Let's cal this image 'gray'\n",
    "2) Invert the grayscale image, which gives a negative image. -> gray^(-1)\n",
    "3) Apply Gaussian blur. -> blurred(gray^(-1)))\n",
    "4) Blend resulting image with the grayscale version (1) using color dodge. -> colorDodge(gray, blurred(gray^(-1))\n",
    "\n",
    "Here, we the following steps are taken:\n",
    "1) Convert the original image to a grayscale image. â€“> gray\n",
    "2) Apply Gaussian blur. -> blurred(gray) \n",
    "3) Pixel-wise divide the grayscale image (1) by the Gaussian blurred image (2). -> gray/blurred(gray)\n",
    "\n",
    "colorDodge actually works by dividing one input by the inverted other input. \n",
    "Thus, the paper inverts an image twice, which brings us back to a non-inverted image. \n",
    "Then it divides these two non-inverted images, which is exactly what happens in step 3 in this code.\n",
    "Conclusion: the steps of the paper and the steps of the code here are mathematically the same.\n",
    "colorDodge(gray, blurred(gray^(-1)) = gray/blurred(gray).\n",
    "''' \n",
    "\n",
    "def preprocess(img):\n",
    "    if img.mode == 'L':\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., None], 2)\n",
    "    else:\n",
    "        return np.rollaxis(np.asarray(img, 'float32')[..., ::-1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovQMUuo_7D2k"
   },
   "source": [
    "**Data class**  \n",
    "The following cell defines the data class. It is used to manage the data (loading, etc.). *You do not have to make any changes to the code.*  \n",
    "*Task*\n",
    "- (1) Study the code and refer to the chainer docuimentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OF39paH6wff"
   },
   "outputs": [],
   "source": [
    "class Dataset(DatasetMixin):\n",
    "    def __init__(self, data_files):\n",
    "        self.data_files = data_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        t = np.asarray(Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS), 'f').transpose(2, 0, 1)\n",
    "        x = pencil_sketch(np.asarray(Image.open(self.data_files[i]).convert('RGB').resize((96, 96), Image.LANCZOS), 'f'))[None]\n",
    "\n",
    "        if device < 0:\n",
    "            return t, x\n",
    "        else:\n",
    "            return cp.asarray(t), cp.asarray(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUjEFdDD6xBq"
   },
   "source": [
    "**Model classes (45 points)**  \n",
    "In the following cellyou will implement the model classes.\n",
    "*Tasks*   \n",
    "- (1) Implement the layers of the model by filling in the missing code. (**20 points**)\n",
    "- (2) Reimplement the model as a ChainList instead of a Chain. (**5 points**)\n",
    "- (3) Implement the forward pass of the residual block by filling in the missing code. (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nafY2Wgx6QLt"
   },
   "outputs": [],
   "source": [
    "class Model(Chain):\n",
    "    def __init__(self, in_channels, outsize):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            # (1) start\n",
    "            self.convolution2D_0 = L.Convolution2D(1, 32, 9, 1, 4, True)\n",
    "            self.batchNormalization_0 = L.BatchNormalization(32)\n",
    "            self.convolution2D_1 = L.Convolution2D(32, 64, 3, 2, 1, True)\n",
    "            self.batchNormalization_1 = L.BatchNormalization(64)\n",
    "            self.convolution2D_2 = L.Convolution2D(64, 128, 3, 2, 1, True)\n",
    "            self.batchNormalization_2 = L.BatchNormalization(128)\n",
    "            self.residualBlock_3 = ResidualBlock(128, 128)\n",
    "            self.residualBlock_4 = ResidualBlock(128, 128)\n",
    "            self.residualBlock_5 = ResidualBlock(128, 128)\n",
    "            self.residualBlock_6 = ResidualBlock(128, 128) \n",
    "            self.residualBlock_7 = ResidualBlock(128, 128)\n",
    "            self.deconvolution2D_8 = L.Deconvolution2D(128, 64, 3, 2, 1, True, outsize = (48, 48))\n",
    "            self.batchNormalization_8 = L.BatchNormalization(64)\n",
    "            # (1) end\n",
    "            self.deconvolution2D_9 = L.Deconvolution2D(64, 32, 3, 2, 1, True, outsize)\n",
    "            self.batchNormalization_9 = L.BatchNormalization(32)\n",
    "            self.convolution2D_10 = L.Convolution2D(32, 3, 9, pad = 4, nobias = True)\n",
    "            self.batchNormalization_10 = L.BatchNormalization(3)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "        #self.add_persistent('mean', np.array([[[[103.939]], [[116.779]], [[123.68]]]], 'float32'))\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = self.batchNormalization_2(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.residualBlock_3(h, finetune = False)\n",
    "        h = self.residualBlock_4(h, finetune = False)\n",
    "        h = self.residualBlock_5(h, finetune = False)\n",
    "        h = self.residualBlock_6(h, finetune = False)\n",
    "        h = self.residualBlock_7(h, finetune = False)\n",
    "        h = self.deconvolution2D_8(h)\n",
    "        h = self.batchNormalization_8(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.deconvolution2D_9(h)\n",
    "        h = self.batchNormalization_9(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_10(h)\n",
    "        h = self.batchNormalization_10(h, finetune = False)\n",
    "        y = 127.5 * F.tanh(h) + 127.5\n",
    "\n",
    "        return y\n",
    "'''\n",
    "class Model(ChainList):\n",
    "    # (2) start\n",
    "    def __init__(self, in_channels, outsize):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "        \n",
    "            ChainList([L.Convolution2D(3, 32, 9, 1, 4, True), L.BatchNormalization(32), L.Convolution2D(32, 64, 3, 2, 1, True), \n",
    "                      L.BatchNormalization(64), L.Convolution2D(64, 128, 3, 2, 1, True), L.BatchNormalization(128), \n",
    "                      ResidualBlock(128, 128), ResidualBlock(128, 128), ResidualBlock(128, 128), \n",
    "                      ResidualBlock(128, 128), ResidualBlock(128, 128), L.Deconvolution2D(128, 64, 3, 2, 1, True), \n",
    "                      L.BatchNormalization(64), L.Deconvolution2D(64, 32, 3, 2, 1, True, outsize), \n",
    "                      L.BatchNormalization(32), L.Convolution2D(32, 3, 9, pad = 4, nobias = True), L.BatchNormalization(3)])\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.outsize = outsize\n",
    "            \n",
    "    def __call__(self, x, finetune = False):\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = self.batchNormalization_2(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.residualBlock_3(h, finetune)\n",
    "        h = self.residualBlock_4(h, finetune)\n",
    "        h = self.residualBlock_5(h, finetune)\n",
    "        h = self.residualBlock_6(h, finetune)\n",
    "        h = self.residualBlock_7(h, finetune)\n",
    "        h = self.deconvolution2D_8(h)\n",
    "        h = self.batchNormalization_8(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.deconvolution2D_9(h)\n",
    "        h = self.batchNormalization_9(h, finetune)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_10(h)\n",
    "        h = self.batchNormalization_10(h, finetune)\n",
    "        y = 127.5 * F.tanh(h) + 127.5\n",
    "\n",
    "        return y\n",
    "    # (2) end '''\n",
    "\n",
    "class ResidualBlock(Chain):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            \n",
    "            self.batchNormalization_0 = L.BatchNormalization(out_channels)\n",
    "            self.batchNormalization_1 = L.BatchNormalization(out_channels)\n",
    "            self.convolution2D_0 = L.Convolution2D( in_channels, out_channels, 3, pad = 1, nobias = True)\n",
    "            self.convolution2D_1 = L.Convolution2D(out_channels, out_channels, 3, pad = 1, nobias = True)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def __call__(self, x, finetune = False):\n",
    "        # (3) start\n",
    "        h = self.convolution2D_0(x)\n",
    "        h = self.batchNormalization_0(h, finetune = False)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = self.batchNormalization_1(h, finetune = False)\n",
    "        y = F.relu(h)\n",
    "        h = h + x\n",
    "        # (3) end\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euDbOQWT1UA8"
   },
   "source": [
    "**Loss classes (45 points)**  \n",
    "In the following cell, you will implement the loss classes.  \n",
    "*Tasks*  \n",
    "- (1) You are provided with a custom VGG-16 implementation. How does it differ than the original implementation? Why can we get away with using the simpler implementation? (**5 points**)\n",
    "- (2) Implement the missing convolution layer of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (3) Implement the forward pass of the total variation loss by filling in the missing code. (**10 points**)\n",
    "- (4) Implement the feature loss component in the forward pass of the loss function by filling in the missing code. (**10 points**)\n",
    "- (5) Explain why the loss components are scaled. (**5 points**)\n",
    "- (6) Explain why the target features are extracted in test mode. (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DqHGhS_1M_x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe weights of the VGG layer should be frozen at all times and should not be re-trained and hence the 'train' configuration \\nis set to false.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Vgg4Layers(Chain):\n",
    "    def __init__(self):\n",
    "        super(Vgg4Layers, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.convolution2D_0 = L.Convolution2D(  3,  64, 3, pad = 1)\n",
    "            self.convolution2D_1 = L.Convolution2D( 64,  64, 3, pad = 1)\n",
    "            self.convolution2D_2 = L.Convolution2D( 64, 128, 3, pad = 1)\n",
    "            self.convolution2D_3 = L.Convolution2D(128, 128, 3, pad = 1)\n",
    "\n",
    "        #self.add_persistent('mean', np.array([[[[103.939]], [[116.779]], [[123.68]]]], 'float32'))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        #x = cupy.asnumpy(x)\n",
    "        #pdb.set_trace()\n",
    "        h = x - F.broadcast_to(self.mean, x.shape)\n",
    "        h = self.convolution2D_0(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = self.convolution2D_2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.convolution2D_3(h)\n",
    "        y = F.relu(h)\n",
    "\n",
    "        return y\n",
    "\n",
    "class TotalVariationLoss(Chain):\n",
    "    def __init__(self):\n",
    "        super(TotalVariationLoss, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.initialW = np.array([3 * [[[-1], [1]]]])\n",
    "            self.initialW2 = np.array([3 * [[[1], [-1]]]])\n",
    "          \n",
    "            self.convolution2D_0 = L.Convolution2D(3, 1, 2, nobias = True, initialW  = self.initialW)   # dtype = 'float32' weggehaald\n",
    "            # (2) start\n",
    "            self.convolution2D_1 = L.Convolution2D(3, 1, 2, nobias = True, initialW = self.initialW2)  # dtype = 'float32' weggehaald\n",
    "            # (2) end\n",
    "            \n",
    "\n",
    "    def __call__(self, x):\n",
    "        # (3) start\n",
    "        y = F.sum(F.sqrt(F.square(self.convolution2D_0(x)) + F.square(self.convolution2D_1(x))))\n",
    "        return y\n",
    "        # (3) end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LossFunction(object):\n",
    "    def __init__(self, lambda_):\n",
    "        if device < 0:\n",
    "            self.totalVariationLoss = TotalVariationLoss()\n",
    "            self.vgg4Layers = Vgg4Layers()\n",
    "            \n",
    "        else:\n",
    "            self.totalVariationLoss = TotalVariationLoss().to_gpu(device)\n",
    "            self.vgg4Layers = Vgg4Layers().to_gpu(device)\n",
    "            \n",
    "\n",
    "    def __call__(self, t, y):            \n",
    "        with chainer.using_config('train', False):\n",
    "            t_ = self.vgg4Layers(t)\n",
    "\n",
    "        # (4) start\n",
    "            y_ = self.vgg4Layers(y)\n",
    "        feature_loss = lambda_['feature'] * F.mean_squared_error(t_, y_)\n",
    "        # (4) end\n",
    "        pixel_loss = lambda_['pixel'] * F.mean_squared_error(t, y)\n",
    "        total_variation_loss = lambda_['total_variation'] * self.totalVariationLoss(y)\n",
    "        loss = feature_loss + pixel_loss + total_variation_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "# (1)\n",
    "\n",
    "'''\n",
    "VGG-16 is a 16 layer deep CNN used for classifying images in the ImageNet challenge. However not all 16 layers\n",
    "are used in this implementation but only the first 4 layers. By extracting only the pre-trained weights of the \n",
    "first 4 layers, the layers containing information about low level features (such as edges and lines) are obtained. \n",
    "Since the detection of these low-level features is mostly task independent (i.e. they don't depend on the images the network\n",
    "was trained on) the already trained layers can interchangebly be used for different problem domains: Thus even though VGG-16\n",
    "was build to classify ImageNet images, the features of the first layers can be helpful for the task of sketch inversion as well. \n",
    "By not having to train a network to detect low level features, computation power and time can be saved. \n",
    "The technique is commonly referred to as transfer learning. \n",
    "'''\n",
    "\n",
    "# (5) \n",
    "'''\n",
    "In the original paper it was observed that the combination of pixel and feature loss increase the image quality of the output\n",
    "pictures. Using feature loss however also introduces some artefacts to the image which can be resolved by adding a small\n",
    "proportion of total variation loss to the loss function. Since only a small proportion was found to resolve the issue, the \n",
    "total variation loss needs to be scaled down.\n",
    "Adding the whole total variation loss might come at a price of the picture's quality since important details of the picture\n",
    "might get lost: Total variation loss aims to minimize the difference between the intensity of neighbouring pixels, however \n",
    "minimizing this intensity too much might result in a picture where clear outlines are not recognizable anymore. \n",
    "'''\n",
    "\n",
    "# (6)\n",
    "'''\n",
    "The weights of the VGG layer should be frozen at all times and should not be re-trained and hence the 'train' configuration \n",
    "is set to false.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nGcCNEy8p3g"
   },
   "source": [
    "**Initialization (10 points)**  \n",
    "The following cell initializes the loss function, the loss history, the model, the optimizer, the datasets and the iterators. *You do not have to make any changes to the code.*  \n",
    "*Tasks*\n",
    "- (1) Study the code and refer to the chainer docuimentation if anything is unclear. You will be expected to write similar code by yourself in the coming practicals. (**0 points**)  \n",
    "- (2) What are the boolean arguments that are passed to the SerialIterator class? (**5 points**)  \n",
    "- (3) Why is it false for the training iterator but not for other iterators? In other words, what would happen if we were to set it to false for the training iterator and true for the other iterators? (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAa-KI4W-3Mm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn case of the training iterator, Shuffle is set to True. This is because the given training_set \\nhas an order that is based on the alphabetical order per person. Thus, the iterator will first \\nlook at all examples of one person, than another, etc. As a consequence, the same person is shown \\nto the model while training, which could make the model biased towards the faces it saw at the \\nstart of the training. I.e., a different order of the input images results in a differently trained \\nmodel. The input images have to be randomized. If not, the model could fail to generalize and thus \\nthe performance during testing and validation will be low.\\nIn case of testing and validation, the order of the images does not matter anymore, since the weights \\nhave already been trained.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossFunction = LossFunction(lambda_)\n",
    "load_npz('{:s}/Vgg4Layers.npz'.format(model_directory), lossFunction.vgg4Layers, strict = False)\n",
    "lossFunction.vgg4Layers.add_persistent('mean', np.array([[[[103.939]], [[116.779]], [[123.68]]]], 'float32'))\n",
    "#load_npz('{:s}/Vgg4Layers.npz'.format(model_directory, epoch), lossFunction.vgg4Layers)\n",
    "loss_history = {'training': [], 'validation': []}\n",
    "model = Model(3, outsize) if device < 0 else Model(3, outsize).to_gpu(device)\n",
    "#model = Model() if device < 0 else Model().to_gpu(device)\n",
    "optimizer = Adam(alpha=1e-5, beta1=0.9, beta2=0.999, eps=1e-09)\n",
    "\n",
    "optimizer.setup(model)\n",
    "\n",
    "data_file = sorted(glob('{}/*.jpg'.format(resize_dir)))\n",
    "training_set = Dataset(data_file[:int(.64 * len(data_file))])\n",
    "validation_set = Dataset(data_file[int(.64 * len(data_file)) : int(.8 * len(data_file))])\n",
    "test_set = Dataset(data_file[int(.8 * len(data_file) ):])\n",
    "training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n",
    "validation_iterator = iterators.SerialIterator(validation_set , batch_size, False, False)\n",
    "test_iterator = iterators.SerialIterator(test_set, batch_test, False, False)\n",
    "\n",
    "\n",
    "# (2)\n",
    "'''\n",
    "The first boolean value is Repeat, the second is Shuffle.\n",
    "- Repeat: if Repeat is False (which is always the case here), the iteration is stopped after \n",
    "going through the whole list once. If Repeat if True (which is never the case here), the iterator \n",
    "loops infintely.\n",
    "- Shuffle: if Shuffle is True, the order of the elements in the given set is randomized at the \n",
    "start of each epoch. If Shuffle is false, the given order is used.\n",
    "'''\n",
    "\n",
    "# (3)\n",
    "'''\n",
    "In case of the training iterator, Shuffle is set to True. This is because the given training_set \n",
    "has an order that is based on the alphabetical order per person. Thus, the iterator will first \n",
    "look at all examples of one person, than another, etc. As a consequence, the same person is shown \n",
    "to the model while training, which could make the model biased towards the faces it saw at the \n",
    "start of the training. I.e., a different order of the input images results in a differently trained \n",
    "model. The input images have to be randomized. If not, the model could fail to generalize and thus \n",
    "the performance during testing and validation will be low.\n",
    "In case of testing and validation, the order of the images does not matter anymore, since the weights \n",
    "have already been trained.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAKIEbqPFzsc"
   },
   "source": [
    "**Training and validation (20 points)**  \n",
    "In the following cell, you will train and validate your model.\n",
    "*Tasks*   \n",
    "- (1) Implement training loss estimation, backprop and parameter update. (**10 points**)\n",
    "- (2) Implement validation loss history (**5 points**)\n",
    "- (3) Implement model serialization  (**5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-pOSKTw0tcK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Iteration number:  0\n"
     ]
    },
    {
     "ename": "CompileException",
     "evalue": "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(55): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(45): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(47): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(48): error: no suitable constructor exists to convert from \"double\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(49): error: no suitable constructor exists to convert from \"int\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(50): error: no suitable constructor exists to convert from \"unsigned int\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(51): error: no suitable constructor exists to convert from \"long long\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(52): error: no suitable constructor exists to convert from \"unsigned long long\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(57): error: no suitable conversion function from \"const half\" to \"float\" exists\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(62): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(66): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(66): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(71): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(75): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(79): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(107): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(107): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(108): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(109): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(110): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(110): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(115): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(115): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(116): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(117): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(119): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(121): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(123): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(123): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(125): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(126): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(128): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(130): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(131): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(133): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(135): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(140): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(140): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(141): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(142): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(275): warning: statement is unreachable\n          detected during instantiation of \"void CIndexer<_ndim>::set(ptrdiff_t) [with _ndim=1]\" \n/tmp/tmp_0y8ad2m/kern.cu(11): here\n\n40 errors detected in the compilation of \"/tmp/tmp_0y8ad2m/kern.cu\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNVRTCError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mnvrtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompileProgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnvrtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPTX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/nvrtc.pyx\u001b[0m in \u001b[0;36mcupy.cuda.nvrtc.compileProgram\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/nvrtc.pyx\u001b[0m in \u001b[0;36mcupy.cuda.nvrtc.compileProgram\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/nvrtc.pyx\u001b[0m in \u001b[0;36mcupy.cuda.nvrtc.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNVRTCError\u001b[0m: NVRTC_ERROR_COMPILATION (6)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCompileException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d38bbdeaed22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration number: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/chainer/dataset/convert.py\u001b[0m in \u001b[0;36mconcat_examples\u001b[0;34m(batch, device, padding)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             result.append(to_device(device, _concat_arrays(\n\u001b[0;32m--> 133\u001b[0;31m                 [example[i] for example in batch], padding[i])))\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/chainer/dataset/convert.py\u001b[0m in \u001b[0;36m_concat_arrays\u001b[0;34m(arrays, padding)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_from_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/manipulation/join.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(tup, axis)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.concatenate_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.concatenate_method\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core._concatenate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core._concatenate_single_kernel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/elementwise.pxi\u001b[0m in \u001b[0;36mcupy.core.core.ElementwiseKernel.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/elementwise.pxi\u001b[0m in \u001b[0;36mcupy.core.core.ElementwiseKernel._get_elementwise_kernel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/elementwise.pxi\u001b[0m in \u001b[0;36mcupy.core.core._get_elementwise_kernel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/elementwise.pxi\u001b[0m in \u001b[0;36mcupy.core.core._get_simple_elementwise_kernel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/elementwise.pxi\u001b[0m in \u001b[0;36mcupy.core.core._get_simple_elementwise_kernel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/carray.pxi\u001b[0m in \u001b[0;36mcupy.core.core.compile_with_cache\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_with_cache\u001b[0;34m(source, options, arch, cache_dir, extra_source)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_using_nvrtc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinkState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ptr_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cupy.ptx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_using_nvrtc\u001b[0;34m(source, options, arch)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NVRTCProgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcu_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCompileException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             dump = _get_bool_env_variable(\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnvrtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNVRTCError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvrtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetProgramLog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCompileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCompileException\u001b[0m: /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(55): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(45): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(47): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(48): error: no suitable constructor exists to convert from \"double\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(49): error: no suitable constructor exists to convert from \"int\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(50): error: no suitable constructor exists to convert from \"unsigned int\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(51): error: no suitable constructor exists to convert from \"long long\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(52): error: no suitable constructor exists to convert from \"unsigned long long\" to \"__half\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(57): error: no suitable conversion function from \"const half\" to \"float\" exists\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(62): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(66): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(66): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(71): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(75): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(79): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(107): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(107): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(108): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(109): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(110): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(110): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(115): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(115): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(116): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(117): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(119): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(121): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(123): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(123): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(125): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(126): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(128): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(130): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(131): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(133): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(135): error: identifier \"ret_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(140): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(140): error: identifier \"__half_raw\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(141): error: expected a \";\"\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(142): error: identifier \"y_raw_\" is undefined\n\n/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/cupy/core/include/cupy/carray.cuh(275): warning: statement is unreachable\n          detected during instantiation of \"void CIndexer<_ndim>::set(ptrdiff_t) [with _ndim=1]\" \n/tmp/tmp_0y8ad2m/kern.cu(11): here\n\n40 errors detected in the compilation of \"/tmp/tmp_0y8ad2m/kern.cu\".\n"
     ]
    }
   ],
   "source": [
    "model.cleargrads()\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss_history['training'].append(0)\n",
    "    print('Epoch: ', i)\n",
    "    #print('Number of iterations: ', len(training_iterator))\n",
    "    training_iterator = iterators.SerialIterator(training_set, batch_size, False, True)\n",
    "    for j, batch in enumerate(training_iterator):\n",
    "        print('Iteration number: ', j)\n",
    "        with chainer.using_config('train', True):\n",
    "            t, x = concat_examples(batch, device)\n",
    "            #print(x)\n",
    "            #pdb.set_trace()\n",
    "            y = model(x)\n",
    "            \n",
    "            # (1) start\n",
    "            #optimizer.setup(model)\n",
    "            loss = lossFunction(t, y)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "            model.cleargrads()\n",
    "            # (1) end\n",
    "            loss_history['training'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['training'][-1] /= (j + 1)\n",
    "    \n",
    "    # (2) start\n",
    "    loss_history['validation'].append(0)\n",
    "    validation_iterator = iterators.SerialIterator(validation_set , batch_size, False, False)\n",
    "    for j, batch in enumerate(validation_iterator):\n",
    "        with chainer.using_config('train', False):\n",
    "            t, x = concat_examples(batch, device)\n",
    "            y_val = model(x)\n",
    "            loss = lossFunction(t, y_val)\n",
    "            loss_history['validation'][-1] += float(loss.data)\n",
    "\n",
    "    loss_history['validation'][-1] /= (j + 1)\n",
    "    # (2) end\n",
    "    #print('Loss history training', loss_history['training'])\n",
    "    #print('Loss history validation', loss_history['validation'])\n",
    "    #print('epoch: {:3d} / {:03d}, training loss: {:.4f}, validation loss: {:.4f}.'.format(i + 1, epochs, loss_history['training'], loss_history['validation']))\n",
    "    print('epoch: {:3d} / {:03d}, training loss: {:.4f}, validation loss: {:.4f}.'.format(i + 1, epochs, loss_history['training'][i], loss_history['validation'][i]))\n",
    "    np.savez('{:s}/loss_history_{:03d}.npz'.format(model_directory, i + 1), loss_history)\n",
    "    # (3) start\n",
    "    save_npz('{:s}/model_{:03d}.npz'.format(model_directory, i + 1), model)\n",
    "    # (3) end\n",
    "    save_npz('{:s}/optimizer_{:03d}.npz'.format(model_directory, i + 1), optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YivB1PQ7Obh"
   },
   "source": [
    "**Test (45 points + 15 bonus points)**  \n",
    "In the following cell, you will test your model.  \n",
    "*Tasks*\n",
    "- (1) Estimate the test loss, print it and save it. (**15 points**)\n",
    "- (2) Estimate the validation metrics, print them and save them (tip: scikit-image) (**15 bonus points**)\n",
    "- (3) Plot example results (i.e., plot a few t, x and y) (**10 points**)\n",
    "- (4) Dicuss your implementation in 300 - 350 words (e.g., how good your results are, how you can improve your model, etc.) (**20 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_npz(os.path.join(model_directory, 'model_004.npz'), lossFunction.vgg4Layers, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdlnCFDS-Cdh"
   },
   "outputs": [],
   "source": [
    "# (1), (2) and (3) start\n",
    "\n",
    "# (1)\n",
    "\n",
    "\n",
    "test_loss = []\n",
    "for j, batch in enumerate(test_iterator):\n",
    "    with chainer.using_config('train', False):\n",
    "        t, x = concat_examples(batch, device)\n",
    "        y_test = model(x)\n",
    "        loss = lossFunction(t, y_test)\n",
    "        \n",
    "    test_loss.append(float(loss.data))\n",
    "    #save_npz('{:s}/testLoss_{:03d}.npz'.format(model_directory, j), test_loss)\n",
    "\n",
    "loss = np.mean(test_loss)\n",
    "#loss_arr = np.asarray(loss)\n",
    "      \n",
    "print(loss)\n",
    "#save_npz('{:s}/testLoss_.npz'.format(model_directory), loss)\n",
    "\n",
    "\n",
    "# (2)\n",
    "psnr = []\n",
    "ssim = []\n",
    "corr = []\n",
    "\n",
    "'''for i, t in enumerate(validation_set):\n",
    "    with chainer.using_config('train', False):\n",
    "        # t is target pencil sketch\n",
    "        y_val1 = model(validation_set[i][0])\n",
    "        pdb.set_trace()\n",
    "        ssim.append(compare_ssim(t, y_val1))\n",
    "        psnr.append(compare_psnr(t, y_val1))\n",
    "        corr.append(np.corrcoef(t, y_val1))'''\n",
    "        \n",
    "for i, batch in enumerate(validation_set):\n",
    "    with chainer.using_config('train', False):\n",
    "        # t is target pencil sketch\n",
    "        t, x = concat_examples(batch, device)\n",
    "        #print(type(validation_set[i]))\n",
    "        y_val1 = model(x)\n",
    "        pdb.set_trace()\n",
    "        ssim.append(compare_ssim(t, y_val1))\n",
    "        psnr.append(compare_psnr(t, y_val1))\n",
    "        corr.append(np.corrcoef(t, y_val1))\n",
    "\n",
    "ssim_fin = np.mean(ssim)\n",
    "psnr_fin = np.mean(psnr)\n",
    "corr_fin = np.mean(corr)\n",
    "\n",
    "print('SSIM: ', ssim_fin)\n",
    "print('PSNR: ', psnr_fin)\n",
    "print('CORR: ', corr_fin)\n",
    "\n",
    "'''save_npz('{:s}/ssim_.npz'.format(model_directory), np.array(ssim_fin).reshape(1,))\n",
    "save_npz('{:s}/psnr_.npz'.format(model_directory), np.array(psnr_fin).reshape(1,))\n",
    "save_npz('{:s}/corr_.npz'.format(model_directory), np.array(corr_fin).reshape(1,))\n",
    "'''\n",
    "# (1), (2) and (3) end\n",
    "fig, subplots = plt.subplots(5, 2, figsize = (15, 10))\n",
    "\n",
    "for i in range(0, 5):\n",
    "    t = test_set[i][0].transpose(1, 2, 0)\n",
    "    x = test_set[i][1].transpose(1, 2, 0)\n",
    "    x_flattened = x.flatten()\n",
    "    x_reshaped = x.reshape(96, 96)\n",
    "\n",
    "    #TODO add the output of model here\n",
    "        \n",
    "    subplots[i][0].imshow(t/256)   #division by 256 because of rgb\n",
    "    subplots[i][0].set_title(\"Target\")\n",
    "    subplots[i][1].imshow(x_reshaped)\n",
    "    subplots[i][1].set_title(\"Input\")\n",
    "\n",
    "# (4)\n",
    "\n",
    "'''\n",
    "The model was trained on a very small data set with 138 images on a CPU machine. Due to a very small training set, the model was\n",
    "harder to train and hence a very low learning rate of 1e-5 was used. The model converges after 6th epoch as can be seen from the\n",
    "training process where the loss goes to 'nan' after the 6th epoch. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "weeks_2_and_3_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
