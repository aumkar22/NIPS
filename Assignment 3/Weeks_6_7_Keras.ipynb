{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as k\n",
    "from keras import optimizers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.engine.topology import Layer\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 2\n",
    "n_z = 20\n",
    "m = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss():\n",
    "    # p_z = gaussian(0,1)\n",
    "    # q_z_x = gaussian(mean_y, e^ln_var_y) - check this exp\n",
    "    # p_x_z = gaissian(mean_x, e^ln_var_x)\n",
    "    # L = F.gaussian_kl_dvergance(q_z_x, p_z) - F.gaussian_nll(p_x_z)\n",
    "        \n",
    "    #? What about input x?\n",
    "        \n",
    "    # Why use log variance instead of variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.int_shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch, dim), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "batches = int(len(x_train)/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        for batch in range(batches):\n",
    "            x = []\n",
    "            \n",
    "            data = x_train[batch * batchsize: (batch + 1) * batchsize]\n",
    "            for i in data:\n",
    "                x.append(np.reshape(i, (28, 28, 1)))\n",
    "            \n",
    "            x_train1 = np.asarray(x)\n",
    "            yield (x_train1, x_train1) # the data is also the target (since we're re-generating images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = Input(shape = (28, 28, 1))\n",
    "\n",
    "encode = Conv2D(32, (2, 2), strides=2, padding = 'same')(inputs1)\n",
    "\n",
    "encode = Activation('relu')(encode)\n",
    "\n",
    "encode = Conv2D(32, (2, 2), strides=2, padding = 'same')(encode)\n",
    "\n",
    "encode = Activation('relu')(encode)\n",
    "\n",
    "out_shape = list(k.int_shape(encode))\n",
    "\n",
    "encode = Flatten()(encode)\n",
    "\n",
    "encode = Dense(512, activation = 'relu')(encode)\n",
    "\n",
    "encode = Dropout(0.5)(encode)\n",
    "\n",
    "mu = Dense(n_z, activation = 'linear')(encode)\n",
    "\n",
    "log_sigma = Dense(n_z, activation = 'linear')(encode)\n",
    "\n",
    "latent_vector = Lambda(sample_z, output_shape=(n_z,))([mu, log_sigma])\n",
    "\n",
    "model_encoder = Model(inputs = inputs1, outputs = [mu, log_sigma, latent_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 32)   160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 32)     4128        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 32)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1568)         0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          803328      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           10260       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 20)           10260       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 20)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 828,136\n",
      "Trainable params: 828,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = Input(shape = (n_z,))\n",
    "\n",
    "decode = Dense(out_shape[1] * out_shape[2] * out_shape[3], activation = 'relu')(inputs2)\n",
    "\n",
    "decode = Reshape((out_shape[1], out_shape[2], out_shape[3]))(decode)\n",
    "\n",
    "decode = Conv2DTranspose(32, (2, 2), strides=2, padding = 'same')(decode)\n",
    "\n",
    "decode = Activation('relu')(decode)\n",
    "\n",
    "decode = Conv2DTranspose(32, (2, 2), strides=2, padding = 'same')(decode)\n",
    "\n",
    "decode = Activation('relu')(decode)\n",
    "\n",
    "out = Conv2DTranspose(1, (2, 2), activation = 'sigmoid', padding = 'same')(decode)\n",
    "\n",
    "model_decoder = Model(inputs = inputs2, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1568)              32928     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         129       \n",
      "=================================================================\n",
      "Total params: 41,313\n",
      "Trainable params: 41,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_decoder(model_encoder(inputs1)[2])\n",
    "model = Model(inputs1, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(None, 20), (None, 20),  828136    \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 28, 28, 1)         41313     \n",
      "=================================================================\n",
      "Total params: 869,449\n",
      "Trainable params: 869,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = binary_crossentropy(K.flatten(inputs1), K.flatten(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss *= image_size * image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = 1 + log_sigma - K.square(mu) - K.exp(log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = K.mean(reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_loss(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_ = optimizers.Adam(lr = 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e970d641eb54b06a094f6cc08b764a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a0f4e2f3974686951b3cecf814514f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(x_train1, batch_size = batches, epochs=10, shuffle = True, verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
