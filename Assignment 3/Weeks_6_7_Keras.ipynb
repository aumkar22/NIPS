{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder():\n",
    "    # Q(z|X)\n",
    "    # l1 = Dense(512, activation = 'relu')\n",
    "    # L2 = Dense(n_z, activation = 'linear') where n_z = number of samples\n",
    "    # Output: mu, log_sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(): \n",
    "    # P(X|z)\n",
    "    # hidden_layer: Dense(512, activation='relu')\n",
    "    # output_layer: Dense(784, activation='sigmoid')\n",
    "    # outputs = output_layer(hidden_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss():\n",
    "    # p_z = gaussian(0,1)\n",
    "    # q_z_x = gaussian(mean_y, e^ln_var_y) - check this exp\n",
    "    # p_x_z = gaissian(mean_x, e^ln_var_x)\n",
    "    # L = F.gaussian_kl_dvergance(q_z_x, p_z) - F.gaussian_nll(p_x_z)\n",
    "        \n",
    "    #? What about input x?\n",
    "        \n",
    "    # Why use log variance instead of variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    eps = K.random_normal(shape=(m, n_z), mean=0., std=1.)\n",
    "    return mu + K.exp(log_sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "batches = int(len(x_train)/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = img_load(data_file[:int(.64 * len(data_file))])\n",
    "validation_set = img_load(data_file[int(.64 * len(data_file)) : int(.8 * len(data_file))])\n",
    "test_set = img_load(data_file[int(.8 * len(data_file) ):])\n",
    "\n",
    "batches = int(len(training_set)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        for batch in range(batches):\n",
    "            \n",
    "            data = x_train[batch * batchsize: (batch + 1) * batchsize]\n",
    "            \n",
    "            # the data is also the target (since we're re-generating images)\n",
    "            yield (data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(batch_generator(), steps_per_epoch = batches, epochs=10, shuffle = True, callbacks = callback_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
