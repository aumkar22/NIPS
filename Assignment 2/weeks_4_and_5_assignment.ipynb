{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSXuZhUcyvhd"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 4 and 5: Assignment (225 points + 30 bonus points)*  \n",
    "Author: Umut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hP3SeQrNyrLC"
   },
   "outputs": [],
   "source": [
    "# Group number: 6\n",
    "# Student 1 name, student 1 number: Aumkar Lele, s4743962\n",
    "# Student 2 name, student 2 number: Djamari Oetringer, s4464559\n",
    "# Student 3 name, student 3 number: Daphne Lenders, s4433556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6Dbkc4t0LNa"
   },
   "outputs": [],
   "source": [
    "from chainer import ChainList, optimizers, serializers\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDhV9ro3HS6"
   },
   "source": [
    "**WaveNet component (75 points)**\n",
    "\n",
    "* Implement missing parts of the call method (y and z). **25 points**\n",
    "* Implement residual block class. **50 points**\n",
    "\n",
    "---\n",
    "Reminder:\n",
    "\n",
    "* One convolution layer that has 61 kernels of size 2 with no nonlinearities.\n",
    "![alt text](http://i67.tinypic.com/21mgi2w.png)\n",
    "![alt text](http://i67.tinypic.com/292n04y.png)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZsQTKPI3Fcy"
   },
   "outputs": [],
   "source": [
    "class _WaveNet(ChainList):\n",
    "    def __init__(self):\n",
    "        links = (L.Convolution2D(61, 61, (1, 2)),)\n",
    "        links += tuple(_ResidualBlock((1, 2 ** (i % 6))) for i in range(6))\n",
    "        links += (L.Convolution2D(512, 512, 1), L.Convolution2D(512, 3843, 1))\n",
    "\n",
    "        super(_WaveNet, self).__init__(*links)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = (self[0](F.pad(x, ((0, 0), (0, 0), (0, 0), (1, 0)), 'constant')),)\n",
    "        z = 0\n",
    "\n",
    "        # Only loop through residual blocks\n",
    "        for i in range(1, len(self) - 2):\n",
    "            y = self[i](y[0]) \n",
    "            z += y[1]\n",
    "\n",
    "        output_relu = F.relu(self[-2](z))\n",
    "        y, z = F.split_axis(self[-1](output_relu), (61 * 61,) , 1)\n",
    "\n",
    "        return F.reshape(y, (y.shape[0], 61, 61, y.shape[3])), \\\n",
    "               F.reshape(z, (z.shape[0], 2, 61, z.shape[3]))\n",
    "\n",
    "class _ResidualBlock(ChainList):\n",
    "    def __init__(self, d):\n",
    "        super(_ResidualBlock, self).__init__(L.DilatedConvolution2D(61, 122, (1,2), dilate = d),\n",
    "                                            L.Convolution2D(61, 573, 1))\n",
    "    \n",
    "    def __call__(self, input_x):\n",
    "    \n",
    "        padded_input = F.pad(input_x, ((0, 0), (0, 0), (0, 0), (self[0].dilate[1], 0)), 'constant')\n",
    "        DC_output = self[0](padded_input) \n",
    "        split = F.split_axis(DC_output, 2, 1) \n",
    "        C_output = self[1](F.sigmoid(split[0]) * F.sigmoid(split[1]))\n",
    "        output = F.split_axis(C_output, (61,), 1)\n",
    "        \n",
    "        return input_x + output[0], output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFoUw1ve3wGY"
   },
   "source": [
    "**CRF-RNN component (50 points)**\n",
    "\n",
    "* Implement missing parts of the call method (z). **25 points**\n",
    "* Why is z not normalized in the last iteration? **25 points**\n",
    "\n",
    "---\n",
    "\n",
    "Reminder:\n",
    "\n",
    "![alt text](http://i68.tinypic.com/sy6mix.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dV1Pd5l3w2ge"
   },
   "outputs": [],
   "source": [
    "class _CRF(ChainList):\n",
    "    def __init__(self):\n",
    "        super(_CRF, self).__init__(L.ConvolutionND(1, 2, 2, 1, nobias = True))\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        z = F.softmax(-y)\n",
    "\n",
    "        for i in range(5):           \n",
    "            # Message passing layer\n",
    "            output_MPL =  F.matmul(z,x)\n",
    "\n",
    "            # Compitability transform layer\n",
    "            output_CTL = self[0](output_MPL)\n",
    "            \n",
    "            # Local update and normalization layer\n",
    "            z = -y - output_CTL\n",
    "\n",
    "            if i < 4:\n",
    "                z = F.softmax(z)\n",
    "\n",
    "        return z\n",
    "    \n",
    "# Why is z not normalized in the last iteration? \n",
    "# The softmax function normalizes each element of an output vector in a scale between 0 and 1, such that the sum over\n",
    "# all elements in the vector is 1. In the first four iterations normalizing is done because this makes training easier and \n",
    "# less computationally expensive. The last iteration is however supposed to give the final actual output of the model. \n",
    "# Thus normalizing wouldn't make much sense here, since we want the actual predicted notes and not a normalized version \n",
    "# of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvbxbgS64Z1Y"
   },
   "source": [
    "**WaveCRF model (50 points)**\n",
    "\n",
    "1. Implement missing parts of the call method (k, psi_u and Q_hat). **20 points**\n",
    "2. Implement missing parts of the save and load methods (save and load model). **10 points**\n",
    "3. Implement missing parts of the test and train methods (forward and/or backward propagate). **20 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACORyKorw_T1"
   },
   "outputs": [],
   "source": [
    "class WaveCRF(object):\n",
    "    def __init__(self):\n",
    "        self.log = {('test', 'accuracy'): (), ('test', 'loss'): (), ('training', 'accuracy'): (),\n",
    "                    ('training', 'loss'): ()}\n",
    "        self.model = ChainList(_WaveNet(), _CRF())\n",
    "        self.optimizer = optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        self.optimizer.setup(self.model)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        k, psi_u = self.model[0](x)\n",
    "        k_transposed = F.transpose(k, (0, 3, 1, 2))\n",
    "        psi_u_transposed = F.transpose(psi_u, (0, 3, 1, 2))\n",
    "        \n",
    "        Q_hat = self.model[1](F.reshape(k_transposed, (-1, 61, 61)),\n",
    "                              F.reshape(psi_u_transposed, (-1, 2, 61)))\n",
    "\n",
    "        return F.transpose(F.reshape(Q_hat, (x.shape[0], x.shape[3], 2, 61)), (0, 2, 3, 1))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, directory):\n",
    "        self = cls()\n",
    "        self.log = np.load('{}/log.npy'.format(directory))\n",
    "\n",
    "        # Load model\n",
    "        serializers.load_npz('{}/model.npz'.format(directory), self.model)\n",
    "        # Load optimizer\n",
    "        serializers.load_npz('{}/optimizer.npz'.format(directory), self.optimizer)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def save(self, directory):\n",
    "        np.save('{}/log.npy'.format(directory), self.log)\n",
    "        # Save model\n",
    "        serializers.save_npz('{}/model.npz'.format(directory), self.model)\n",
    "        # Save optimizer\n",
    "        serializers.save_npz('{}/optimizer.npz'.format(directory), self.optimizer)\n",
    "\n",
    "    def test(self, Q, x):\n",
    "        with chainer.using_config('train', False):\n",
    "            # Forward Prop\n",
    "            Q_hat = self(x)\n",
    "            loss = F.softmax_cross_entropy(Q_hat, Q)\n",
    "\n",
    "            #self.log['test', 'accuracy'] += (float(F.accuracy(Q_hat, Q).data),)\n",
    "            #self.log['test', 'loss'] += (float(loss.data),)\n",
    "            return Q_hat\n",
    "\n",
    "    def train(self, Q, x):\n",
    "        # Forward prop\n",
    "        Q_hat = self(x)\n",
    "        loss = F.softmax_cross_entropy(Q_hat, Q)\n",
    "\n",
    "        # Backprop\n",
    "        self.model.cleargrads()\n",
    "        loss.backward()\n",
    "        self.optimizer.update()\n",
    "\n",
    "        self.log['training', 'accuracy'] += (float(F.accuracy(Q_hat, Q).data),)\n",
    "        self.log['training', 'loss'] += (float(loss.data),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN6H9URT926N"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import IPython\n",
    "import chainer\n",
    "import matplotlib\n",
    "import numpy\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tS3Y0yWwb3r"
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epochs = 3\n",
    "root = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRcSp6shwg_Y"
   },
   "outputs": [],
   "source": [
    "with open('Data/piano_rolls.p'.format(root), 'rb') as f:\n",
    "    piano_rolls = pickle.load(f)\n",
    "    \n",
    "keys = sorted(piano_rolls.keys())\n",
    "\n",
    "random.seed(6)\n",
    "random.shuffle(keys)\n",
    "\n",
    "test_set = dict((key, piano_rolls[key]) for key in keys[:int(0.1 * len(keys))])\n",
    "training_set = dict((key, piano_rolls[key]) for key in keys[int(0.1 * len(keys)):])\n",
    "training_set_keys = list(training_set.keys())\n",
    "\n",
    "\n",
    "with open('test_set.pkl', 'wb') as f:\n",
    "        pickle.dump(test_set, f, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUVzWwIJwjQ7"
   },
   "outputs": [],
   "source": [
    "waveCRF = WaveCRF()\n",
    "\n",
    "#waveCRF.model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zWuKZ1EwlKa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm.tnrange(epochs):\n",
    "    random.shuffle(training_set_keys)\n",
    "\n",
    "    batch = ()\n",
    "\n",
    "    for key in tqdm.tqdm_notebook(training_set_keys, leave = False):\n",
    "        i = random.randint(0, training_set[key].shape[1] - 80)\n",
    "        batch += (training_set[key][32 : 93, i : i + 80],)\n",
    "\n",
    "        if len(batch) == batch_size:\n",
    "            batch = waveCRF.model.xp.array(batch)\n",
    "\n",
    "            waveCRF.train(batch[:, :, 1:].astype('i'), batch[:, :, None, :-1].astype('f'))\n",
    "\n",
    "            batch = ()\n",
    "\n",
    "    for key in tqdm.tqdm_notebook(test_set, leave = False):\n",
    "        batch = waveCRF.model.xp.array((test_set[key][32 : 93],))\n",
    "\n",
    "        waveCRF.test(batch[:, :, 1:].astype('i'), batch[:, :, None, :-1].astype('f'))\n",
    "\n",
    "    IPython.display.clear_output()\n",
    "\n",
    "    for i, key in enumerate(waveCRF.log):\n",
    "        matplotlib.pyplot.subplot(221 + i)\n",
    "        matplotlib.pyplot.plot(numpy.array(waveCRF.log[key]).reshape(epoch + 1, -1).mean(1))\n",
    "        matplotlib.pyplot.xlabel('iteration')\n",
    "        matplotlib.pyplot.ylabel(key)\n",
    "\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "    os.makedirs('{}/Models/WaveCRF/{}'.format(root, epoch))\n",
    "    waveCRF.save('{}/Models/WaveCRF/{}'.format(root, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NqNHKCblzY52"
   },
   "source": [
    "**Test (50 points)**  \n",
    "\n",
    "* Generate a number of samples, pick the best one and play it in the notebook. **50 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('./midi')\n",
    "import midi.utils\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "from chainer import ChainList, optimizers, serializers\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveCRF = WaveCRF().load('../Models/WaveCRF/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our softmax function\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum( np.exp(x))\n",
    "    return ex/sum_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PGOJ_hHzZDg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test_set = np.load('test_set.npy')\\nprint(len(test_set))\\n# Test\\n\\nfor key in test_set:\\n    batch = waveCRF.model.xp.array((test_set[key][32 : 93],))\\n    print(batch.shape)\\n    output = waveCRF.test(batch[:, :, 1:].astype('i'), batch[:, :, None, :-1].astype('f'))\\n    print(output.shape)\\n\\nfor key in tqdm.tqdm_notebook(test_set, leave = False):\\n    \\n    batch = waveCRF.model.xp.array((test_set[key][32 : 93],))\\n    print(batch)\\n    output = waveCRF.test(batch[:, :, 1:].astype('i'), batch[:, :, None, :-1].astype('f'))\\n    sounds = output.array\\n    #print(sounds.shape)\\n    \\n    for i in (range(sounds.shape[3])):\\n        print(sounds[:,:,:,i])\\n    #midi.utils.midiwrite('piano_roll.mid', piano_roll.T, (32, 93), 0.25) \\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open model and save it\n",
    "#get output for one batch \n",
    "#take the probabilities from the dimension with 2\n",
    "#first probability: probability that note is not played (check this)\n",
    "#second probability: probability that note is played (check this)\n",
    "#generate random number: if it's higher than first probability number the note is played\n",
    "#do this for all 61 notes to generate new timestamp vector\n",
    "#concatinate this vector to the input that was given in the first place\n",
    "#repeat multiple time\n",
    "\n",
    "\n",
    "with open('test_set.pkl', 'rb') as f:\n",
    "        test_set = pickle.load(f)\n",
    "\n",
    "\n",
    "first_key = test_set.keys()[0]\n",
    "first_value = test_set[first_key]\n",
    "input_x = first_value[32 : 93]\n",
    "\n",
    "midi.utils.midiwrite('original.mid', input_x.T, (32, 93), 0.25) \n",
    "\n",
    "for i in range(100):\n",
    "    batch = waveCRF.model.xp.array((input_x,))\n",
    "    output = waveCRF.test(batch[:, :, 1:].astype('i'), batch[:, :, None, :-1].astype('f'))\n",
    "    output = F.softmax(output)\n",
    "\n",
    "    note_is_not_played = output[0,0,:,:].array    \n",
    "    note_is_played = output[0,1,:,:].array\n",
    "\n",
    "    last_time_played = note_is_played[:,-1]\n",
    "    last_time_not_played = note_is_not_played[:,-1]\n",
    "\n",
    "\n",
    "    output = []\n",
    "    for i in range(len(last_time_played)):\n",
    "        prob_played = last_time_played[i]\n",
    "        prob_not_played = last_time_not_played[i]\n",
    "        coin_flip = np.random.random_sample()\n",
    "        if coin_flip <= prob_played:\n",
    "            output.append([True])\n",
    "        else:\n",
    "            output.append([False])\n",
    "\n",
    "    input_x = np.hstack((input_x, output))\n",
    "\n",
    "\n",
    "#piano_roll = np.random.rand(61, 79) < .5\n",
    "midi.utils.midiwrite('output.mid', input_x.T, (32, 93), 0.25) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qX69DLwW_yMx"
   },
   "source": [
    "**Bonus question (30 points)**\n",
    "\n",
    "* _Discuss how you can improve the model (you can talk about different architectures or different ways to encode the inputs, etc.) **10 points*_*\n",
    "\n",
    "* _Discuss the assumptions behind the meanfield approximation and its shortcomings. **10 points*_*\n",
    "\n",
    "The assumption of the mean field approximation is that the probability of a series of notes occuring together, is the same as the joint probablity of each note occuring seperately. This assumption is somewhat naive, since there are certain combination of notes that sounds very melodic together while others combinations might not sound nice at all. Thus knowing that one note occurs can change the probability of another note occuring at the same time. \n",
    "However making this assumption also saves a lot of computational power since one doesn't have to worry about all possible conditional probabilites that may exist between notes.  \n",
    "\n",
    "* _Prove that the iterative update equation (CRF-RNN component) is differentiable so that we can backpropagate through them. **10 points*_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qX69DLwW_yMx"
   },
   "source": [
    "**Bonus question (30 points)**\n",
    "\n",
    "* _Discuss how you can improve the model (you can talk about different architectures or different ways to encode the inputs, etc.) **10 points*_*\n",
    "\n",
    "* _Discuss the assumptions behind the meanfield approximation and its shortcomings. **10 points*_*\n",
    "\n",
    "The assumption of the mean field approximation is that the probability of a series of notes occuring together, is the same as the joint probablity of each note occuring seperately. This assumption is somewhat naive, since there are certain combination of notes that sounds very melodic together while others combinations might not sound nice at all. Thus knowing that one note occurs can change the probability of another note occuring at the same time. \n",
    "However making this assumption also saves a lot of computational power since one doesn't have to worry about all possible conditional probabilites that may exist between notes.  \n",
    "\n",
    "* _Prove that the iterative update equation (CRF-RNN component) is differentiable so that we can backpropagate through them. **10 points*_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "weeks_4_and_5_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
