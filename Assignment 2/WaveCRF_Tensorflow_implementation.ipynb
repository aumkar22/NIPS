{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSXuZhUcyvhd"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 4 and 5: Assignment (225 points + 30 bonus points)*  \n",
    "Author: Umut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hP3SeQrNyrLC"
   },
   "outputs": [],
   "source": [
    "# Group number: 6\n",
    "# Student 1 name, student 1 number: Aumkar Lele, s4743962\n",
    "# Student 2 name, student 2 number: Djamari Oetringer, s4464559\n",
    "# Student 3 name, student 3 number: Daphne Lenders, s4433556\n",
    "\n",
    "# Comment: We made two implementations of the WaveCRF model, one using Chainer, the other one using Tensorflow. The Chainer \n",
    "# model is complete and working and thus also the model we would like to hand in for grading. The Tensorflow model is \n",
    "# not completely working yet, so if you could provide us some feedback on what's going wrong/what's missing, that would\n",
    "# be really useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from time import time\n",
    "import tqdm\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "layers = tf.contrib.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdDhV9ro3HS6"
   },
   "source": [
    "**WaveNet component (75 points)**\n",
    "\n",
    "* Implement missing parts of the call method (y and z). **25 points**\n",
    "* Implement residual block class. **50 points**\n",
    "\n",
    "---\n",
    "Reminder:\n",
    "\n",
    "* One convolution layer that has 61 kernels of size 2 with no nonlinearities.\n",
    "![alt text](http://i67.tinypic.com/21mgi2w.png)\n",
    "![alt text](http://i67.tinypic.com/292n04y.png)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "data_directory = os.path.join(root_dir, 'piano_roll_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('piano_rolls.p'), 'rb') as f:\n",
    "    piano_rolls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = sorted(piano_rolls.keys())\n",
    "\n",
    "random.seed(6)\n",
    "random.shuffle(keys)\n",
    "\n",
    "test_set = dict((key, piano_rolls[key]) for key in keys[:int(0.1 * len(keys))])\n",
    "training_set = dict((key, piano_rolls[key]) for key in keys[int(0.1 * len(keys)):])\n",
    "training_set_keys = list(training_set.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(y, i, par_conv_sum):\n",
    "    \n",
    "    short = y\n",
    "    \n",
    "    padded_input = tf.pad(y, [[0, 0], [0, 0], [0, 0], [i, 0]], mode='CONSTANT')\n",
    "    \n",
    "    y_ = layers.conv2d(padded_input, 122, kernel_size = 2, stride = 1, rate = i, data_format = 'NCHW')\n",
    "    \n",
    "    split1, split2 = tf.split(y_, [61, 61], axis = 1)\n",
    "    y1 = layers.conv2d(split1, 61, kernel_size = 2, stride = 1, rate = i, data_format = 'NCHW')\n",
    "    y2 = layers.conv2d(split2, 61, kernel_size = 2, stride = 1, rate = i, data_format = 'NCHW')\n",
    "\n",
    "    y1_tan = tf.nn.tanh(y1)\n",
    "    y2_sig = tf.nn.sigmoid(y2)\n",
    "\n",
    "    y_mul = tf.multiply(y1_tan, y2_sig)\n",
    "    \n",
    "    parallel_conv1 = layers.conv2d(y_mul, 61, kernel_size = 1, stride = 1, data_format = 'NCHW')\n",
    "    \n",
    "    parallel_conv2 = layers.conv2d(y_mul, 512, kernel_size = 1, stride = 1,  data_format = 'NCHW', activation_fn = tf.nn.relu)\n",
    "    \n",
    "    y_1 = tf.add(short, parallel_conv1)\n",
    "         \n",
    "    if i != 32:\n",
    "        \n",
    "        if i == 1:\n",
    "            return y_1, parallel_conv2\n",
    "        else:\n",
    "            return y_1, tf.add(parallel_conv2, par_conv_sum)\n",
    "        \n",
    "    elif i == 32:\n",
    "        return tf.add(parallel_conv2, par_conv_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _crf(k, psi_u):\n",
    "    \n",
    "    q = psi_u\n",
    "    \n",
    "    #Message passing layer\n",
    "    y = tf.nn.softmax(psi_u, axis = 1)\n",
    "    y_ = tf.matmul(tf.transpose(y, perm = [0, 3, 1, 2]), tf.transpose(k, perm = [0, 3, 1, 2]))\n",
    "    \n",
    "    \n",
    "    #Compatibility transform layer\n",
    "    y_1 = tf.transpose(y_, perm = [0, 2, 1, 3])\n",
    "    \n",
    "    ctl = layers.conv2d(y_1, 2, kernel_size = 1, stride = 1, data_format = 'NCHW')\n",
    "    \n",
    "    #Local update and normalization layer\n",
    "    \n",
    "    z = tf.subtract(tf.transpose(-psi_u, perm = [0, 3, 1, 2]), ctl)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        if i == 4:\n",
    "            return tf.transpose(z, perm = [0, 2, 3, 1])\n",
    "            \n",
    "        elif i < 4:\n",
    "            z = tf.nn.softmax(z, axis = 1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def waveCRF(input_):\n",
    "\n",
    "    padded_input = tf.pad(input_, [[0, 0], [0, 0], [0, 0], [1, 0]], mode='CONSTANT') # (batch_size, channels, notes, time)\n",
    "\n",
    "    model = layers.conv2d(padded_input, 61, kernel_size = [1, 2], data_format = 'NCHW')\n",
    "    \n",
    "    model_shape = model.get_shape().as_list()\n",
    "    \n",
    "    conv_init = tf.zeros([batch_size, 512, model_shape[2], model_shape[3]], tf.float32)\n",
    "    \n",
    "    res1, sum1 = residual_block(model, 1, conv_init)\n",
    "\n",
    "    res2, sum2 = residual_block(res1, 2, sum1)\n",
    "\n",
    "    res3, sum3 = residual_block(res2, 4, sum2)\n",
    "\n",
    "    res4, sum4 = residual_block(res3, 8, sum3)\n",
    "\n",
    "    res5, sum5 = residual_block(res4, 16, sum4)\n",
    "\n",
    "    res6 = residual_block(res5, 32, sum5)\n",
    "\n",
    "    model_ = layers.conv2d(res6, 3843, kernel_size = 1, stride = 1, data_format = 'NCHW')\n",
    "\n",
    "    out1, out2 = tf.split(model_, [3721, 122], axis = 1)\n",
    "\n",
    "    out_shape1 = out1.get_shape().as_list()\n",
    "\n",
    "    out_shape2 = out2.get_shape().as_list()\n",
    " \n",
    "    wave_out1 = tf.reshape(out1, (out_shape1[0], 61, 61, out_shape1[2] * out_shape1[3]))  #k\n",
    "\n",
    "    wave_out2 = tf.reshape(out2, (out_shape2[0], 2, 61, out_shape2[2] * out_shape2[3]))  #psi_u\n",
    "    \n",
    "    return _crf(wave_out1, wave_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for epoch in tqdm.tnrange(epochs):\n",
    "        random.shuffle(training_set_keys)\n",
    "\n",
    "        batch = ()\n",
    "\n",
    "        for key in tqdm.tqdm_notebook(training_set_keys, leave = False):\n",
    "            i = random.randint(0, training_set[key].shape[1] - 80)\n",
    "            batch += (training_set[key][32 : 93, i : i + 80],)\n",
    "\n",
    "            if len(batch) == batch_size:\n",
    "                batch = np.asarray(batch)\n",
    "                \n",
    "                Q = batch[:, :, 1:].astype('i')\n",
    "                input_ = batch[:, :, None, :-1].astype('f')\n",
    "                Q_hat = waveCRF(input_)\n",
    "                \n",
    "                t_vars = tf.trainable_variables()\n",
    "                train_loss = tf.losses.softmax_cross_entropy(Q, logits = Q_hat)\n",
    "                Optimizer = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.9, \n",
    "                                                   beta2=0.999, epsilon=1e-8).minimize(train_loss, var_list = t_vars)\n",
    "                _, lossV, _trainY, _predict = sess.run([Optimizer, train_loss, \n",
    "                                                        tf.convert_to_tensor(Q, dtype=tf.float32), \n",
    "                                                        tf.convert_to_tensor(Q_hat, dtype=tf.float32)])\n",
    "                _label = np.argmax(_trainY, axis=1)\n",
    "                _accuracy = np.mean(_label == _predict)\n",
    "                plt.plot('loss', lossV)\n",
    "                plt.plot('train accuracy', _accuracy)\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "weeks_4_and_5_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
