{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as k\n",
    "from keras import optimizers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.engine.topology import Layer\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "n_z = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the sample function needed to combine the encoder and decoder model.\n",
    "\n",
    "Task: (20 points)\n",
    "\n",
    "- Implement the reparameterziation trick for sampling latents. (10 points)\n",
    "- Explain why we need to use this trick. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.int_shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch, dim), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_sigma / 2) * eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why we need to use this trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "batches = int(len(x_train)/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        for batch in range(batches):\n",
    "            x = []\n",
    "            \n",
    "            data = x_train[batch * batchsize: (batch + 1) * batchsize]\n",
    "            for i in data:\n",
    "                x.append(np.reshape(i, (28, 28, 1)))\n",
    "            \n",
    "            x_train1 = np.asarray(x)\n",
    "            yield (x_train1, x_train1) # the data is also the target (since we're re-generating images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for the encoder. It transforms observables (images) to latents (features). It corresponds to q(z | x) in the context of variational inference (and the slides), where z is latents and x is observables.\n",
    "\n",
    "Task: (10 points)\n",
    "\n",
    "- Implement the encoder class for a variational autoencoder. Note that the encoder should output the Gaussian distribution parameters (mean and variance per feature) of features rather than features themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = Input(shape = (28, 28, 1))\n",
    "\n",
    "encode = Conv2D(32, (2, 2), strides=2, padding = 'same')(inputs1)\n",
    "\n",
    "encode = Activation('relu')(encode)\n",
    "\n",
    "encode = Conv2D(32, (2, 2), strides=2, padding = 'same')(encode)\n",
    "\n",
    "encode = Activation('relu')(encode)\n",
    "\n",
    "out_shape = list(k.int_shape(encode))\n",
    "\n",
    "encode = Flatten()(encode)\n",
    "\n",
    "encode = Dense(420, activation = 'relu')(encode)\n",
    "\n",
    "encode = Dropout(0.5)(encode)\n",
    "\n",
    "mu = Dense(n_z, activation = 'linear')(encode)\n",
    "\n",
    "log_sigma = Dense(n_z, activation = 'linear')(encode)\n",
    "\n",
    "latent_vector = Lambda(sample_z, output_shape=(n_z,))([mu, log_sigma])\n",
    "\n",
    "model_encoder = Model(inputs = inputs1, outputs = [mu, log_sigma, latent_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for the decoder. It transforms latents (features) to observables (images). It corresponds to p(x | z) in the context of variational inference (and the slides), where x is observables and z is latents.\n",
    "\n",
    "Task: (10 points)\n",
    "\n",
    "- Implement the decoder class for a variational autoencoder. Note that the decoder should output the Gaussian distribution parameters (mean and variance per pixel) of images rather than images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = Input(shape = (n_z,))\n",
    "\n",
    "decode = Dense(out_shape[1] * out_shape[2] * out_shape[3], activation = 'relu')(inputs2)\n",
    "\n",
    "decode = Reshape((out_shape[1], out_shape[2], out_shape[3]))(decode)\n",
    "\n",
    "decode = Conv2DTranspose(32, (2, 2), strides=2, padding = 'same')(decode)\n",
    "\n",
    "decode = Activation('relu')(decode)\n",
    "\n",
    "decode = Conv2DTranspose(32, (2, 2), strides=2, padding = 'same')(decode)\n",
    "\n",
    "decode = Activation('relu')(decode)\n",
    "\n",
    "out = Conv2DTranspose(1, (2, 2), activation = 'sigmoid', padding = 'same')(decode)\n",
    "\n",
    "model_decoder = Model(inputs = inputs2, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_decoder(model_encoder(inputs1)[2])\n",
    "model = Model(inputs1, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the loss class. The loss of encoder and decoder of a variational autoencoder is the evidence lower bound as follows:\n",
    "\n",
    "$L = D_{KL}(q(z | x), p(z)) -  E_{z\\sim q}[log p(x | z)]$\n",
    "\n",
    "The first term above is the KL divergence between the approximate posterior (q) and the prior (p), which can be interpreted as a form of regularization. You can assume that the prior is unit Gaussian. It can be implemented with the F.gaussian_kl_divergence function in Chainer.\n",
    "\n",
    "The second term above is the Gaussian negative log likelihood. This is the term that fits the data, which is very similar to the usual loss functions that you use in deep learning. It can be implemented with the F.gaussian_nll function in Chainer.\n",
    "\n",
    "Task: \n",
    "\n",
    "- Implement the loss class. (10 points)\n",
    "- Explain why we use log variance instead of variance. (5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss(y_true, y_pred):\n",
    "    reconstruction_loss = image_size * image_size * binary_crossentropy(K.flatten(y_true), K.flatten(y_pred))\n",
    "    kl_loss = -0.5 * K.sum(1 + log_sigma - K.square(mu) - K.exp(log_sigma), axis=-1)\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    \n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why we use log variance instead of variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_ = optimizers.Adam(lr = 1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam_, loss = _loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(batch_generator(), steps_per_epoch = batches, epochs = 10, shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
